{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DI 501 Assignment 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due: November 22, Wednesday by 23:30\n",
    "---\n",
    "\n",
    "### Submission and Grading Principles\n",
    "\n",
    "**Assignment Submission Guidelines:**\n",
    "\n",
    "* Submit your assignments via the assignment module on [ODTUClass](https://odtuclass.metu.edu.tr).\n",
    "\n",
    "* You will work on this file, and rename it as \"*name_surname_a1.ipynb*\" (e.g., \"*volga_sezen_a1.ipynb*\").\n",
    "\n",
    "* Late submissions will be accepted until November 26, Sunday by 23:30, with a 10% penalty per day.\n",
    "\n",
    "* **<font color=#C91515>This is an individual assignment; do not collaborate, and uphold academic integrity principles.</font>**\n",
    "\n",
    "* Offer insightful commentary about your results. Data understanding relies on your reasoning; not just numbers, tables, or graphics.\n",
    "\n",
    "* Include your code in the designated code blocks and your commentary in markdown blocks.\n",
    "<br>*You can, of course, use multiple code blocks.* **Make sure printouts and graphs are visible before submission.**\n",
    "\n",
    "------------\n",
    "\n",
    "### The aim of this assignment is getting you familiar with:\n",
    "\n",
    "* Python and Jupyter notebooks,\n",
    "\n",
    "* Data cleaning,\n",
    "\n",
    "* Descriptive statistics interpretation,\n",
    "\n",
    "* Visualization methods, and\n",
    "\n",
    "* Statistical tests\n",
    "\n",
    "------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will work with data from the \"Indo-U.S. CoudÃ© Feed Stellar Spectra Library\" which is a catalogue of stars in the sky.\n",
    "\n",
    "This dataset is a merger of two tables which includes metadata and calculations derived from observations conducted at Kitt Peak, Arizona. \n",
    "\n",
    "Each row represents a unique star, and you will analyze various attributes associated with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General characteristics:\n",
    "\n",
    "| Variable Name | Explanation |\n",
    "|---|---|\n",
    "| index | Name of the star in main catalogues |\n",
    "| SpType | Spectral class of the star [$^{1}$](#notes)|\n",
    "| RA | Right ascension, or $\\alpha$. ($^{\\circ}$, eq = J2000) [$^{2}$](#notes)|\n",
    "| DEC | Declination, or $\\delta$. ($^{\\circ}$, eq = J2000) |\n",
    "\n",
    "Observational parameters:\n",
    "\n",
    "| Variable Name | Explanation |\n",
    "|---|---|\n",
    "| B | Measured brightness of the B(lue) filter (mag) [$^{3}$](#notes)|\n",
    "| V | Measured brightness of the V(isible) filter (mag) |\n",
    "| RV | Radial velocity (along line of sight) of the star (Km/s) [$^{4}$](#notes)|\n",
    "| Teff | Estimated effective temperature of the star surface (Kelvin) |\n",
    "| e_Teff | Window of uncertainty for surface temperature |\n",
    "| log(g) | Log of estimated surface gravity (Dex, $10^x$, compared to the Sun) |\n",
    "| e_log(g) | Window of uncertainty for surface gravity |\n",
    "| [Fe/H] | Estimated metallicity (Dex, $10^x$, compared to the Sun) [$^{5}$](#notes)|\n",
    "| e_[Fe/H] | Window of uncertainty for metallicity |\n",
    "\n",
    "Other miscellaneous columns:\n",
    "\n",
    "| Variable Name | Explanation |\n",
    "|---|---|\n",
    "| lum | Luminosity class extracted from SpType |\n",
    "| misc | Any peculiarities about the spectra extracted from SpType |\n",
    "| PHYSREF | References to the literature regarding estimation of the physical parameters |\n",
    "| Names | Other names for the star in different catalogues for cross-referencing |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Made up of three components, temperature class (B1 for ex.), luminosity class (Roman numeral), and other reported oddities.\n",
    "\n",
    "    > First two are labeled according to Morgan-Keenan-Kellman classification system. <br>\n",
    "    > \n",
    "    > * The temperature class has two parts, a letter (main spectral type), and a digit (subtype).  \n",
    "    >   * The main sequence follows this order: O, B, A, F, G, K, M, excluding newer types. <br> The sun is classified as G5. Here 5    signifies the sun is right in-between G0 and G9. <br>\n",
    "    >\n",
    "    > \n",
    "    > * Luminosity class is shown by roman numerals from I to VI, with I having a or b suffix only.\n",
    "\n",
    "2. Equitorial astronomical coordinate. ra/dec is analogous to the x/y direction, but represents coordinates inside a sphere, <br> and thus coordinates wrap around.\n",
    "\n",
    "3. Defined in the UBV photometric system as the following: <br>B filter has a mean wavelength response of 442 nm, while for V the mean response is at 540 nm.\n",
    "\n",
    "4. i.e. the speed at which the star is moving toward or away from Earth. Estimated by the doppler effect.\n",
    "\n",
    "5. i.e. proportion of metals (elements heavier than helium) to hydrogen in the star's chemical makeup."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Environment setup\n",
    "Import numpy, pandas, matplotlib, seaborn, statsmodels and scipy, along with other libraries you may utilize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill here ##\n",
    "# Path: DI 501 Assignment 1.ipynb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import random\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Initial inspection (5p)\n",
    "\n",
    "1. Load the data given with the correct separator.\n",
    "\n",
    "1. Show how many observations and features are present.\n",
    "\n",
    "1. Then show the last 6 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill here ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Data cleaning and augmentation (15p)\n",
    "\n",
    "**Assume you are a data scientist working on stellar distributions. You care about all of the columns of this dataset, especially ones on physical characteristics and fields relating to research.**\n",
    "\n",
    "1.  * Report how many NA values are present in each column, and the value count of NA's in rows. (How many rows have 0,1,2... NA's)\n",
    "\n",
    "    * Then show the **correlation** of missingness between columns via missingno's heatmap.\n",
    "\n",
    "    * Devise a strategy to get rid of columns and rows with NA's. (*The order matters here!*) Define your thresholds and report them clearly.\n",
    "    \n",
    "    * After removing NA's print the shape of the dataset.\n",
    "<br>\n",
    "<br>\n",
    "2.  * Define a new variable called \"spec\" that only consists of the main spectral class. (First capital letter in SpType) \n",
    "    \n",
    "    * Then, generate a variable called \"sub\" that only consists of the subclass. (First digit in SpType).\n",
    "    \n",
    "    * Combine them using string addition to create a final variable called \"type\".\n",
    "<br>\n",
    "<br>\n",
    "3. Normalize column names to be lowercase AND to not contain any non-letter character.\n",
    "\n",
    "4. Show that your solutions worked by calling the info method of the dataframe.\n",
    "\n",
    "*Hint: You will benefit a lot from using [regular expressions](https://images.datacamp.com/image/upload/v1665049611/Marketing/Blog/Regular_Expressions_Cheat_Sheet.pdf) and [lambda functions](https://www.datacamp.com/tutorial/python-lambda) here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill here ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Interpreting descriptive statistics (15p)\n",
    "\n",
    "Just by looking at descriptive statistics (and no graphs yet) of each numeric column determine whether they possess a left-skewed,<br>  right-skewed, or a symmetric distribution. *You don't have to give definite answers, but rather explain which category feels closest.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill here ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fill here by double clicking me!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Visualizing distributions (15p)\n",
    "\n",
    "1. Visualize the distributions of numeric variables and determine whether they are close to a gaussian distribution or not.<br>Provide additional commentary for any peculiarities you spot. (*You can use subplots and loops to put multiple graphs inside the same figure.*)\n",
    "\n",
    "1. For the categorical variables, use appropriate visualisations and comment on whether the sample is balanced or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill here ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fill here by double clicking me!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Quantile-Quantile plots and hypothesis testing (15p)\n",
    "\n",
    "1.  * Select a variable that looks like it has a normal distribution, rid it of any NA values and sort it. Assign it to a new array.\n",
    "    \n",
    "    * Create an array called \"s1\" filled with random numbers sampled from the standard normal distribution. $(\\mu = 0,\\ \\ \\sigma = 1)$ \n",
    "    <br>Then sort this array in an ascending order. Make sure this array has equal length to the array above.\n",
    "    \n",
    "    * Assemble a scatter plot with s1 in the x axis and your variable without NA's in y axis. Then draw on top (or to the side) a qqplot of your variable using stasmodels.\n",
    "\n",
    "<br>\n",
    "\n",
    "2.  * This time, select a variable that has a right skewed distribution, and repeat the operations above.\n",
    "\n",
    "    * Next, create a similar array called \"s2\", but this time sample from the log-normal distribution. $(\\mu = 0,\\ \\ \\sigma = 1)$\n",
    "\n",
    "    * Assemble another scatterplot using seaborn's `regplot` function. Set `robust=True` and `ci=None` for the regression fit to be <br> robust to outliers coming from random sampling. Also draw another statsmodels qqplot next to it, or on top.\n",
    "\n",
    "    Do the plots you generate resemble statsmodels' qqplots?<br><br>**Explain how the similarities came about, as well as any differences.**\n",
    "\n",
    "3.  * Then apply the shapiro-wilk normality test onto the two variables you chose. \n",
    "\n",
    "    * State the null hypothesis, find the test statistic and p value for each, the level of significance you chose when evaluating the hypotheses and your final judgement on both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill here ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fill here by double clicking me!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Correlations (15p)\n",
    "\n",
    "Generate a pairwise pearson correlation matrix of numeric columns, visualise them with correlation coefficients visible and comment on any potentially interesting relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fill here by double clicking me!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Testing the spectral sequence (20p)\n",
    "\n",
    "1. * Use graphs (or `groupby`) to see which of the physical characteristics can explain the star's class. (The column you created named 'spec'.)\n",
    "        <br>In other words, select which features would you use in order to seperate classes easily by straight lines, and plot the distributions of those features for each class.\n",
    "<br>\n",
    "<br><br>\n",
    "\n",
    "2. * Then test the claim that the mean log(g) of A class stars is less than mean log(g) for B class stars using a paired t test. \n",
    "    <br>*Note that there may not be the same number of A class and B class stars. Sample the bigger class down to the size of the smaller one.*\n",
    "    \n",
    "   * Like usual, state your null hypothesis, calculate the test statistic, choose a significance level and find a p value using stats package and finally give your judgement on the hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill here ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fill here by double clicking me!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "209a8a79b62b9a15fabcb5c2874ba5edf5459f9f2ed3af08edfe2caeb3e2f87f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
